# Hashing: Complete Notes with Internal Implementation (C++/Java/Python) and FAQs

## üîπ Introduction to Hashing

Hashing is a technique used to convert a given key into an index in an array (called a hash table). This index determines where the key-value pair should be stored in the hash table. The core objective of hashing is to ensure quick **insertions, deletions, and lookups** in average-case **O(1)** time.

---

## üîπ Need for Hashing

- Data is growing rapidly, and we need a way to **store, access, and retrieve** it efficiently.
- Arrays support **O(1)** insertion but **O(n)** or **O(log n)** search.
- Hashing enables **O(1)** average time complexity for search, insert, delete.

---

## üîπ Components of Hashing

| Component     | Description                                                                |
| ------------- | -------------------------------------------------------------------------- |
| Key           | Unique identifier (string, int)                                            |
| Hash Function | Converts key into hash code or index                                       |
| Hash Table    | An array where data is stored based on the index provided by the hash code |

---

## üîπ How Hashing Works

1. Convert the key into a hash code using a **hash function**.
2. Use **modulo operation** with hash table size to determine index.
3. Insert the key-value pair at the computed index.
4. If multiple keys map to same index (collision), use collision resolution.

[](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcfXm7wGLcCpmVSe9HGi2kXa_8FRPQudTEQiBT4B3o-wxZJIeA3ztrKBpy6i70B6qmK3tol0Xtuza8fQbfBxh7JOJ3VBH5FucCN_3D3eZlHhvXz7XekQw1ljtCQn03vZsTBdGT7szDkPlX0LwvOxi25q45A?key=g8kDN9zvdrw-DqjRV8ue8Q)

                                                *Mapping key with indices of array*

Example:

```
Key: "ab" = 1 + 2 = 3
Key: "cd" = 3 + 4 = 7
Key: "efg" = 5 + 6 + 7 = 18
Table size = 7
Index = sum % 7
Indexes: "ab" ‚Üí 3, "cd" ‚Üí 0, "efg" ‚Üí 4

```

---

## üîπ Hash Function Types

The hash function creates a mapping between key and value, this is done through the use of mathematical formulas known as hash functions. The result of the hash function is referred to as a hash value or hash. The hash value is a representation of the original string of characters but usually smaller than the original.

For example: Consider an array as a Map where the key is the index and the value is the value at that index. So for an array A if we have index **i** which will be treated as the key then we can find the value by simply looking at the value at A[i].

simply looking up A[i].

1. **Division Method**: `h(k) = k % m`
2. **Mid Square Method**: Square the key, use middle digits.
3. **Folding Method**: Break into parts, add.
4. **Multiplication Method**: `h(k) = floor(m*(k*A % 1))`

---

## üîπ Good Hash Function Properties

A hash function that maps every item into its own unique slot is known as a perfect hash function. We can construct a perfect hash function if we know the items and the collection will never change but the problem is that there is no systematic way to construct a perfect hash function given an arbitrary collection of items. Fortunately, we will still gain performance efficiency even if the hash function isn‚Äôt perfect. We can achieve a perfect hash function by increasing the size of the hash table so that every possible value can be accommodated. As a result, each item will have a unique slot. Although this approach is feasible for a small number of items, it is not practical when the number of possibilities is large.

So, We can construct our hash function to do the same but the things that we must be careful about while constructing our own hash function.

- Efficiently computable
- Uniformly distributes keys
- Minimize collisions
- Low load factor (<= 0.75)

## **Problem with Hashing**

If we consider the above example, the hash function we used is the sum of the letters, but if we examined the hash function closely then the problem can be easily visualized that for different strings the same hash value is generated by the hash function.

For example: {‚Äúab‚Äù, ‚Äúba‚Äù} both have the same hash value, and string {‚Äúcd‚Äù,‚Äùbe‚Äù} also generate the same hash value, etc. This is known as **collision** and it creates problems in searching, insertion, deletion, and updating of value.

---

## üîπ What is a Collision?

- A collision occurs when two keys map to the same index.
- Must be handled to avoid overwriting.

[What is Collision in Hashing](https://lh7-rt.googleusercontent.com/docsz/AD_4nXe1sbEeFlF0Rc2H2zYlH18QTT7knaHwNR1QKGaD0no4khrCYPM5mWoxShjYAT0bVeSdrA6kNeeskq43KokbPbk3X19iCbWi9yrD6YAPB_QiSaDytG4e7Mq_zN6qOkFojDagGgAu0Pw_s8u4CiOyl_xynEuY?key=g8kDN9zvdrw-DqjRV8ue8Q)

---

## üîπ Collision Resolution Techniques

### 1. Separate Chaining

The idea is to make each cell of the hash table point to a linked list of records that have the same hash function value. Chaining is simple but requires additional memory outside the table.

Example: We have given a hash function and we have to insert some elements in the hash table using a separate chaining method for collision resolution technique.

Hash function = key % 5,

Elements = 12, 15, 22, 25 and 37.

Let‚Äôs see step by step approach to how to solve the above problem:

- **Step 1:** First draw the empty hash table which will have a possible range of hash values from 0 to 4 according to the hash function provided.

[Hash table](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdr_kapCcgl_1BP_j3i-0EvdD4e6XOTeHG5D2FFpRm-8jeeErDhOUq0uAQuuYRn9NqA2aKH_o0QMW_pa-i9iwkjc8YF_2KvNthK1e2B5SDqNa7q17osnZKWAqC453RWCk0xF2DS6X2L_GbwOPF6GzrrXUsi?key=g8kDN9zvdrw-DqjRV8ue8Q)

_Hash table_

- **Step 2:** Now insert all the keys in the hash table one by one. The first key to be inserted is 12 which is mapped to bucket number 2 which is calculated by using the hash function 12%5=2.

[step1](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcze08UMtv0cddTnvaQMHMMhBHlYyi5B4dXc8uK5QXhZ1pbYW1Eh2cbuztXUhY5GKU6okUR5J5_vgbfzoFH6CvDCABzpO5o2kJ6aGTMQon6wtgY4uaYiq5PUovsjXVWihkaGQDgLsqSrMzRAh51D8aO2X8l?key=g8kDN9zvdrw-DqjRV8ue8Q)

_Insert 12_

- **Step 3:** Now the next key is 22. It will map to bucket number 2 because 22%5=2. But bucket 2 is already occupied by key 12.

[step2](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc_MGYkdwXWEUURIQVOSCtyLVx-euht8pidgqj4w6rZQamQ26wgPhA5G3Vxv9O5OkcrCz5GsMbZ4b0dBEoINe8fUZdmkZSPtB4dpLFsQXSFrmUmN4ZT3V4rzIVQPT55mK-QZ2rFwoFsmclw1-qNl0AzF9k?key=g8kDN9zvdrw-DqjRV8ue8Q)

_Insert 22_

- **Step 4:** The next key is 15. It will map to slot number 0 because 15%5=0.

[step3](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeYWA7XoWOjFN0bikxkUKZmaGQ7tg95oTIJOO7ikexMvTEf9nFchSthVIIORNQQE-DDmfTRSaXeCKj6WxaiBRNjmeVV8C22SFcAndWozrfaoGP8R6fHK0_LI7zxIxBIzKZGvJmojdVjt1YcQvyR8VCbiW9e?key=g8kDN9zvdrw-DqjRV8ue8Q)

                                                                  *Insert 15*

- **Step 5:** Now the next key is 25. Its bucket number will be 25%5=0. But bucket 0 is already occupied by key 25. So a separate chaining method will again handle the collision by creating a linked list to bucket 0.

[step4](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcpnTrurGZbC3ONVoGV07d6YAGPUOkUjpeCpL9u8k_e597GMQ94nQX-A4r8ZH1eZzcqp8iHLNjC6zzaU2PtMinYzehuXVnWuVVzSN6kruvzyLE_AnXM3ThIzv5AclIU19Yk3f-GerTbIb3KKM3R5Q2uhKAj?key=g8kDN9zvdrw-DqjRV8ue8Q)

_Insert 25_

Hence In this way, the separate chaining method is used as the collision resolution technique.

- Each index points to a linked list.
- All elements with same hash index are stored in the list.

### ‚úÖ 2. Open Addressing

### a) Linear Probing

- If index is full, try next: `(index + 1) % table_size`

### b) Quadratic Probing

- Try: `(index + i^2) % table_size`

### c) Double Hashing

- Use second hash function:
- `index = (h1(k) + i * h2(k)) % size`

---

## üîπ Load Factor & Rehashing

The load factor of the hash table can be defined as the number of items the hash table contains divided by the size of the hash table. Load factor is the decisive parameter that is used when we want to rehash the previous hash function or want to add more elements to the existing hash table.

It helps us in determining the efficiency of the hash function i.e. it tells whether the hash function which we are using is distributing the keys uniformly or not in the hash table.

### Load Factor:

`Load Factor = no. of elements / table size`

### Rehashing:

As the name suggests, rehashing means hashing again. Basically, when the load factor increases to more than its predefined value (the default value of the load factor is 0.75), the complexity increases. So to overcome this, the size of the array is increased (doubled) and all the values are hashed again and stored in the new double-sized array to maintain a low load factor and low complexity.

- When load factor > 0.75, resize table (usually double it) and re-insert all elements.

---

## üîπ Applications of Hashing

- Database indexing
- Symbol tables in compilers
- Caching
- Cryptography (e.g., password hashing)
- Pattern matching algorithms (e.g., Rabin-Karp)

## **Advantages of Hash Data structure**

- Hash provides better synchronization than other data structures.
- Hash tables are more efficient than search trees or other data structures
- Hash provides constant time for searching, insertion, and deletion operations on average.

## **Disadvantages of Hash Data structure**

- Hash is inefficient when there are many collisions.
- Hash collisions are practically not avoided for a large set of possible keys.
- Hash does not allow null values

---

## üîπ Hashing in Different Languages

### ‚ú® C++:

- `std::map`: Uses Red-Black Tree (O(log n))
- `std::unordered_map`: Uses Hash Table (O(1) average, O(n) worst-case)

### ‚ú® Java:

- `HashMap` uses array of nodes (`Node<K, V>`)
- Each bucket is a singly linked list or tree (for high collisions)
- Uses `hashCode()` and `equals()`
- Index = `hashCode & (n - 1)`

### ‚ú® Python:

- `dict` is implemented using a hash table
- `OrderedDict`: maintains insertion order
- Python 3.7+: `dict` preserves order too

---

## Internal Working of Hashing in C++

### std::map

- Based on Balanced Binary Search Trees (e.g., AVL Tree, Red-Black Tree).
- **Time Complexity:** O(log n) for insertions, deletions, and lookups.
- Maintains keys in sorted order.
- During insertion, comparisons are made to find the right position.
- The maximum number of comparisons is equivalent to the height of the tree (log n).

### std::unordered_map

- Based on **Hash Tables**.
- **Average Time Complexity:** O(1)
- **Worst-Case Time Complexity:** O(n) due to **collisions**.
- Hash function computes an index where the key-value pair is placed.
- Collisions are handled using chaining (linked lists or buckets).

---

## Internal Working of HashMap in Java

### Structure of HashMap:

- Contains an array of **Node<K,V>** objects.
- Each `Node` contains:
  - `int hash`
  - `K key`
  - `V value`
  - `Node next` (for collision handling via LinkedList)

### Hashing Process:

- Uses `hashCode()` method to convert key to an integer.
- Example:

```java
@Override
public int hashCode() {
    return (int) key.charAt(0); // ASCII of first char
}

```

### Index Calculation:

```java
index = hashCode(key) & (n - 1);

```

Where `n` is the size of the internal array.

### Collision Handling:

- If two keys map to the same index:
  - Compare using `equals()`.
  - If equal: update the value.
  - If not equal: store using LinkedList chaining.

### Buckets:

- Each index in the internal array is a bucket.
- Load factor determines rehashing threshold.
- Multiple entries in one bucket use LinkedLists or TreeNodes (for high collision chains).

### Null Key:

- One `null` key is allowed.
- Placed at index 0.

### get() and put() Methods:

- `put()`: calculates hash and index ‚Üí stores or updates key-value.
- `get()`: calculates index ‚Üí traverses bucket using equals().

### Time Complexity:

- **Best/Average Case:** O(1)
- **Worst Case:** O(n) (due to collisions)

---

## TreeMap in Java

- Based on **Red-Black Tree**.
- Keys are **always sorted** in natural order or custom comparator.
- Each node has references to **parent, left, right**.
- **Time Complexity:** O(log n)
- Does not allow **null keys** but allows multiple **null values**.
- **Not thread-safe**.

---

## Dictionary in Python

### dict:

- Stores key-value pairs.
- Since Python 3.6 (CPython), **insertion order is preserved**.
- As of Python 3.7, this behavior is part of the language spec.

### Internal Working:

- Backed by **Hash Table**.
- Each bucket stores:
  - Hash of key
  - Key object
  - Value object
  - Pointer (or index) in case of collisions

### Time Complexity:

- **Average Case:** O(1) for get, set, delete
- **Worst Case:** O(n) due to collisions OrderedDict (Python)

---

### Features:

- Subclass of `dict`, preserves **insertion order**.
- Useful when **ordering** is critical to the logic.
- Available from `collections` module.

### Differences from dict:

| Feature                            | dict      | OrderedDict          |
| ---------------------------------- | --------- | -------------------- |
| Insertion order preserved          | ‚úÖ (3.7+) | ‚úÖ                   |
| Performance                        | ‚ö° Faster | üö∂ Slower            |
| Memory Usage                       | üîΩ Lower  | üîº Higher            |
| Reverse Iteration                  | ‚úÖ (3.8+) | ‚úÖ (3.5+)            |
| Equality considers order           | ‚ùå        | ‚úÖ                   |
| .move_to_end(), .popitem(last=...) | ‚ùå        | ‚úÖ                   |
| Can have custom attributes         | ‚ùå        | ‚úÖ (via `.__dict__`) |

### Methods:

- `.move_to_end(key, last=True/False)`: Move key to front or end.
- `.popitem(last=True/False)`: Pop first or last item.

### Use Case: Queue using OrderedDict

```python
from collections import OrderedDict

class Queue:
    def __init__(self):
        self.data = OrderedDict()

    def enqueue(self, key, value):
        if key in self.data:
            self.data.move_to_end(key)
        self.data[key] = value

    def dequeue(self):
        return self.data.popitem(last=False)

```

## Frequently Asked Questions (FAQs)

---

### 1. **How does HashMap work internally?**

A `HashMap` is internally implemented as an **array of buckets**, where each bucket is essentially a **linked list** or a **red-black tree** (for high-collision scenarios). Each bucket stores **Node<K, V>** objects containing the key, value, hash, and a pointer to the next node.

The workflow is:

1. The key‚Äôs `hashCode()` is computed.
2. This hash is transformed to an index using:

   `index = hash & (array.length - 1)`.

3. If the bucket is empty, a new node is inserted.
4. If not, the existing nodes are checked using `equals()` to avoid duplicate keys.
5. If a match is found ‚Üí update value; else ‚Üí add a new node via chaining.
6. If the bucket becomes too crowded, it may convert the linked list to a **red-black tree** to maintain efficient operations.

---

### 2. **How does the `remove()` method work in HashMap?**

The `remove()` method deletes the entry for a given key and returns the associated value (or `null` if the key doesn't exist).

Steps:

1. Compute the hash and index for the key.
2. Go to the bucket at that index.
3. Traverse the linked list/tree to find the key using `equals()`.
4. If found, adjust pointers to remove the node from the chain/tree.
5. Return the removed value; if not found, return `null`.

> In tree-based buckets, removal follows red-black tree deletion logic to maintain balance.

---

### 3. **Why are HashMap keys considered unchangeable (immutable)?**

Although `HashMap` doesn‚Äôt enforce immutability, it‚Äôs **strongly recommended** that keys be immutable because:

- The key‚Äôs `hashCode()` is used to determine its position (bucket) in the map.
- If the key is **mutated after insertion**, its `hashCode()` may change, making it **impossible to retrieve** the value, as it will look in the wrong bucket.
- Common immutable types used as keys: `String`, `Integer`, `Long`, etc.

Mutable keys may cause **data inconsistency, memory leaks**, or **silent retrieval failures**.

---

### 4. **What type of data structure does HashMap use internally?**

Internally, `HashMap` uses:

- An **array** of buckets
- Each bucket is either:
  - A **LinkedList** (for chaining entries with same index)
  - A **TreeNode** (for large chains: ‚â• 8 entries, when array size ‚â• 64)

This hybrid structure (array + linked list/tree) ensures:

- **Fast average performance** (O(1) for `get`/`put`)
- **Efficient worst-case performance** (O(log n) when collisions are high and trees are used)

---

‚úÖ Let me know if you'd like a **visual diagram** or **Java code examples** to reinforce these concepts.

---

## üîπ Summary Table

| Language | Structure Used                  | Avg. Time | Handles Collisions        | Maintains Order |
| -------- | ------------------------------- | --------- | ------------------------- | --------------- |
| C++      | `unordered_map` (hash table)    | O(1)      | Separate chaining         | No              |
| Java     | `HashMap` (array + linked list) | O(1)      | Chaining + Tree if needed | No              |
| Python   | `dict` (hash table)             | O(1)      | Open addressing           | Yes (3.7+)      |
| Python   | `OrderedDict`                   | O(1)      | Linked list + hash table  | Yes             |

---
